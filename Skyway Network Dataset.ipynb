{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06f1a0c-d9b7-44e4-a4e7-1e92cd323a29",
   "metadata": {},
   "source": [
    "# Skyway Network Dataset Generation Notebook\n",
    "**Paper Title**: Optimizing QoS fulfillment of Drone Services\n",
    "\n",
    "**Conference Submission**: International Conference on Service-Oriented Computing, 2025\n",
    "\n",
    "**Purpose**  \n",
    "This notebook constructs the skyway network used as the operational environment for drone delivery flights, as presented in the paper. It provides all the necessary steps to reproduce the dataset from raw building data of the Sydney CBD area.\n",
    "\n",
    "**Overview**  \n",
    "- **Step 1**: Extracts raw building data from OpenStreetMap for the Sydney CBD area. Extracted attributes include:\n",
    "  - Building height  \n",
    "  - Building type  \n",
    "  - GPS coordinates  \n",
    "  - Building names  \n",
    "  - Rooftop area  \n",
    "- **Step 2**: Cleans and preprocesses the data to remove incomplete or invalid entries. \n",
    "- **Step 3**: Constructs the skyway network:\n",
    "  - Nodes serve as the buildings' rooftops. Each node has a varying number of charging and waiting pads based on the usable rooftop area.\n",
    "  - Line-of-Sight (LoS) segments serve as aerial space for drones to transit between nodes. The area of each skyway segment is defined based on the regulatory measures. \n",
    "\n",
    "**Instructions**  \n",
    "- Run **all cells in order** to fully reproduce the dataset.  \n",
    "\n",
    "**Dependencies**  \n",
    "- Python 3.x  \n",
    "- pandas  \n",
    "- numpy  \n",
    "- osmnx  \n",
    "- shapely  \n",
    "- networkx  \n",
    "(Ensure all required packages are installed before execution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85073e5f-79fb-4269-b2e2-1865b213746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import folium\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import concurrent.futures\n",
    "from geopy.distance import geodesic\n",
    "from math import radians, sin, cos, atan2, sqrt\n",
    "from itertools import combinations\n",
    "from shapely.geometry import box, Point, Polygon\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62225324-0f5a-43a0-898a-a88a392c5482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retrieved 187 raw elements near (-33.873245725325454, 151.20711588465713)\n",
      "ðŸ“„ Output written to 'Sydney_Buildings.csv'\n",
      "âœ… Total nodes saved: 87\n"
     ]
    }
   ],
   "source": [
    "def fetch_nearby_buildings_by_count(lat, lon, max_nodes=2500, output_file='Sydney_Buildings.csv'):\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json][timeout:60];\n",
    "    (\n",
    "      way[\"building\"=\"apartments\"](around:1000,{lat},{lon});\n",
    "      way[\"amenity\"=\"restaurant\"](around:1500,{lat},{lon});\n",
    "      way[\"amenity\"=\"cafe\"](around:1500,{lat},{lon});\n",
    "      node[\"shop\"=\"supermarket\"](around:800,{lat},{lon})[\"name\"~\"Woolworths|Coles\"];\n",
    "    );\n",
    "    out center {max_nodes};\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(overpass_url, params={'data': overpass_query}, timeout=90)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return\n",
    "\n",
    "    data = response.json()\n",
    "    elements = data.get(\"elements\", [])\n",
    "    if not elements:\n",
    "        print(\"No nearby buildings found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"âœ… Retrieved {min(len(elements), max_nodes)} raw elements near ({lat}, {lon})\")\n",
    "\n",
    "    # Counters for each type\n",
    "    type_counts = {\n",
    "        \"apartments\": 0,\n",
    "        \"restaurant\": 0,\n",
    "        \"cafe\": 0,\n",
    "        \"supermarket\": 0\n",
    "    }\n",
    "\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "        fieldnames = [\"Node_ID\", \"Node\", \"Type\", \"Latitude\", \"Longitude\", \"GPS_coordinates\", \"Estimated_Height\"]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        node_id_counter = 1\n",
    "\n",
    "        for element in elements:\n",
    "            tags = element.get('tags', {})\n",
    "            name = tags.get('name', '').strip()\n",
    "            if not name:\n",
    "                continue\n",
    "\n",
    "            lat_val = element.get('center', {}).get('lat') or element.get('lat')\n",
    "            lon_val = element.get('center', {}).get('lon') or element.get('lon')\n",
    "            if lat_val is None or lon_val is None:\n",
    "                continue\n",
    "\n",
    "            element_type = (\n",
    "                tags.get('amenity') or\n",
    "                tags.get('shop') or\n",
    "                tags.get('building') or\n",
    "                'Unknown'\n",
    "            )\n",
    "\n",
    "            if element_type not in type_counts:\n",
    "                continue\n",
    "\n",
    "            # For apartments only, estimate and filter by height\n",
    "            if element_type == \"apartments\":\n",
    "                height = None\n",
    "                if 'height' in tags:\n",
    "                    try:\n",
    "                        height = float(tags['height'])\n",
    "                    except ValueError:\n",
    "                        height = None\n",
    "                elif 'building:levels' in tags:\n",
    "                    try:\n",
    "                        levels = float(tags['building:levels'])\n",
    "                        height = levels * 3  # Approx. 3m per level\n",
    "                    except ValueError:\n",
    "                        height = None\n",
    "\n",
    "                if height is None or height <= 30 or height >= 120:\n",
    "                    continue  # skip apartments that don't meet height condition\n",
    "            else:\n",
    "                height = None  # not required for other types\n",
    "\n",
    "            writer.writerow({\n",
    "                \"Node_ID\": f\"Node_{node_id_counter}\",\n",
    "                \"Node\": name,\n",
    "                \"Type\": element_type,\n",
    "                \"Latitude\": lat_val,\n",
    "                \"Longitude\": lon_val,\n",
    "                \"GPS_coordinates\": f\"{lat_val}, {lon_val}\",\n",
    "                \"Estimated_Height\": height\n",
    "            })\n",
    "\n",
    "            type_counts[element_type] += 1\n",
    "            node_id_counter += 1\n",
    "\n",
    "            if node_id_counter > max_nodes:\n",
    "                break\n",
    "\n",
    "    print(f\"ðŸ“„ Output written to '{output_file}'\")\n",
    "    print(f\"âœ… Total nodes saved: {sum(type_counts.values())}\")\n",
    "\n",
    "# --- Run the function ---\n",
    "fetch_nearby_buildings_by_count(\n",
    "    lat=-33.873245725325454,\n",
    "    lon=151.20711588465713,\n",
    "    max_nodes=2500,\n",
    "    output_file='Sydney_Buildings.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65e14572-b7b2-4d77-9bf3-d6eead0fc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning dataset- removing duplicates\n",
    "df = pd.read_csv(\"Sydney_Buildings.csv\")  # replace with your actual CSV file\n",
    "\n",
    "# Drop duplicate rows based on the GPS_coordinates column\n",
    "df_unique = df.drop_duplicates(subset=['GPS_coordinates'])\n",
    "df_unique.to_csv(\"Sydney_Buildings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a320eb17-ab1f-4b47-8e26-4dea5cd18ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning dataset- removing Unnamed nodes\n",
    "df = pd.read_csv(\"Sydney_Buildings.csv\")\n",
    "\n",
    "# Drop rows where Node_Name is \"Unnamed\" (case-insensitive, leading/trailing spaces removed)\n",
    "df_cleaned = df[~df['Node'].str.strip().str.lower().eq('unnamed')]\n",
    "df_cleaned.to_csv(\"Sydney_Buildings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ec587b2-f4d0-4747-9e47-291fa4925b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query Overpass for building height\n",
    "def fetch_building_height(lat, lon, radius=10):\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:25];\n",
    "    (\n",
    "      way[\"building\"](around:{radius},{lat},{lon});\n",
    "      node[\"building\"](around:{radius},{lat},{lon});\n",
    "    );\n",
    "    out body;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(overpass_url, params={'data': query})\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        for element in data.get('elements', []):\n",
    "            tags = element.get('tags', {})\n",
    "            if 'height' in tags:\n",
    "                try:\n",
    "                    return float(tags['height'])\n",
    "                except ValueError:\n",
    "                    pass  # Non-numeric value, skip\n",
    "            elif 'building:levels' in tags:\n",
    "                try:\n",
    "                    return float(tags['building:levels']) * 3  # Estimate: 3 meters per level\n",
    "                except ValueError:\n",
    "                    pass  # Non-numeric levels, skip\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching for ({lat}, {lon}): {e}\")\n",
    "    return None\n",
    "\n",
    "# Function to process a single row\n",
    "def process_row(i_row):\n",
    "    i, row = i_row\n",
    "    lat, lon = row['Latitude'], row['Longitude']\n",
    "    height = fetch_building_height(lat, lon)\n",
    "    if height is None:\n",
    "        btype = row['Type'].strip().lower() if isinstance(row['Type'], str) else ''\n",
    "        if btype != 'apartments':\n",
    "            height = 80\n",
    "    return i, height\n",
    "\n",
    "df = pd.read_csv(\"Sydney_Buildings.csv\")\n",
    "df['Building_Height'] = None\n",
    "\n",
    "# Run parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    for i, height in executor.map(process_row, df.iterrows()):\n",
    "        df.at[i, 'Building_Height'] = height\n",
    "\n",
    "df.to_csv(\"Sydney_Buildings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07b0b3fa-bb79-4679-9b2b-90ff0463af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Sydney_Buildings.csv\")\n",
    "\n",
    "#cleaning dataset-removing buildings with no height fetched\n",
    "# Replace empty strings with NaN if any\n",
    "df['Building_Height'].replace('', pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows where Building_Height is NaN\n",
    "df_cleaned = df.dropna(subset=['Building_Height'])\n",
    "df_cleaned.to_csv(\"Sydney_Buildings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db1771ef-f4fe-4507-976f-b5e088217123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for obstructing nodes for generating LoS-based skyway segments\n",
    "def haversine_distance(coord1, coord2):\n",
    "    lat1, lon1 = map(float, coord1.split(','))\n",
    "    lat2, lon2 = map(float, coord2.split(','))\n",
    "    R = 6371.0  \n",
    "    lat1_rad, lon1_rad = radians(lat1), radians(lon1)\n",
    "    lat2_rad, lon2_rad = radians(lat2), radians(lon2)\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    a = sin(dlat / 2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def find_obstructing_nodes(node1_idx, node2_idx, nodes_data, distance_threshold=0.001):\n",
    "    obstructing_nodes = []\n",
    "    \n",
    "    gps1 = nodes_data.at[node1_idx, 'GPS_coordinates']\n",
    "    gps2 = nodes_data.at[node2_idx, 'GPS_coordinates']\n",
    "    height1 = nodes_data.at[node1_idx, 'Building_Height']\n",
    "    height2 = nodes_data.at[node2_idx, 'Building_Height']\n",
    "    total_distance = haversine_distance(gps1, gps2)\n",
    "    max_height = max(height1, height2)\n",
    "\n",
    "    for idx, row in nodes_data.iterrows():\n",
    "        if idx != node1_idx and idx != node2_idx:\n",
    "            gps_ob = row['GPS_coordinates']\n",
    "            height_ob = row['Building_Height']\n",
    "            if height_ob > max_height:\n",
    "                d1 = haversine_distance(gps1, gps_ob)\n",
    "                d2 = haversine_distance(gps2, gps_ob)\n",
    "                if abs(d1 + d2 - total_distance) < distance_threshold:\n",
    "                    obstructing_nodes.append({\n",
    "                        'Node_Pair': f'{node1_idx}-{node2_idx}',\n",
    "                        'Node1': nodes_data.at[node1_idx, 'Node'],\n",
    "                        'Node1_Type': nodes_data.at[node1_idx, 'Type'],\n",
    "                        'Node2': nodes_data.at[node2_idx, 'Node'],\n",
    "                        'Node2_Type': nodes_data.at[node2_idx, 'Type'],\n",
    "                        'Obstructing_Nodes': row['Node'],\n",
    "                        'GPS_Coordinates_Node1': gps1,\n",
    "                        'GPS_Coordinates_Node2': gps2,\n",
    "                        'GPS_Coordinates_Obstruction': gps_ob,\n",
    "                        'Height_Node1': height1,\n",
    "                        'Height_Node2': height2,\n",
    "                        'Height_Obstruction': height_ob\n",
    "                    })\n",
    "\n",
    "    if not obstructing_nodes:\n",
    "        obstructing_nodes.append({\n",
    "            'Node_Pair': f'{node1_idx}-{node2_idx}',\n",
    "            'Node1': nodes_data.at[node1_idx, 'Node'],\n",
    "            'Node1_Type': nodes_data.at[node1_idx, 'Type'],\n",
    "            'Node2': nodes_data.at[node2_idx, 'Node'],\n",
    "            'Node2_Type': nodes_data.at[node2_idx, 'Type'],\n",
    "            'Obstructing_Nodes': None,\n",
    "            'GPS_Coordinates_Node1': gps1,\n",
    "            'GPS_Coordinates_Node2': gps2,\n",
    "            'GPS_Coordinates_Obstruction': None,\n",
    "            'Height_Node1': height1,\n",
    "            'Height_Node2': height2,\n",
    "            'Height_Obstruction': None\n",
    "        })\n",
    "    return obstructing_nodes\n",
    "\n",
    "def generate_obstruction_csv(nodes_data):\n",
    "    result_data = []\n",
    "    node_combinations = combinations(nodes_data.index, 2)  # For Unique pairs of nodes\n",
    "    for node1_idx, node2_idx in node_combinations:\n",
    "        result_data.extend(find_obstructing_nodes(node1_idx, node2_idx, nodes_data))\n",
    "    pd.DataFrame(result_data).to_csv('obstruction_data_check.csv', index=False)\n",
    "\n",
    "\n",
    "building_data = pd.read_csv('Sydney_Buildings.csv', encoding='utf-8-sig')\n",
    "generate_obstruction_csv(building_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "840c83a2-530a-408c-a435-f85a11e8f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "obstruction_data = pd.read_csv('obstruction_data_check.csv')\n",
    "\n",
    "# Function to calculate Haversine distance between two GPS coordinates\n",
    "def haversine_distance(coord1, coord2):\n",
    "    R = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1 = map(radians, map(float, coord1.split(', ')))\n",
    "    lat2, lon2 = map(radians, map(float, coord2.split(', ')))\n",
    "    # Calculate the differences in coordinates\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    # Haversine formula\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    # Calculate the distance\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "obstruction_data['Edge_Length (Km)'] = obstruction_data.apply(lambda row: haversine_distance(row['GPS_Coordinates_Node1'], row['GPS_Coordinates_Node2']), axis=1)\n",
    "obstruction_data.to_csv('obstruction_data_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42766fcd-ddf4-4517-b524-8d486b8fd960",
   "metadata": {},
   "outputs": [],
   "source": [
    "obstruction_data = pd.read_csv('obstruction_data_check.csv')\n",
    "\n",
    "# Create an empty graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Iterate through the rows of the dataset to add nodes and edges to the graph\n",
    "for index, row in obstruction_data.iterrows():\n",
    "    node1 = row['Node1']\n",
    "    node2 = row['Node2']\n",
    "    obstructing_nodes = row['Obstructing_Nodes']\n",
    "    edge_length = row.get('Edge_Length (Km)', 1.0) \n",
    "    if pd.isna(obstructing_nodes) and edge_length < 2.0:\n",
    "        graph.add_edge(node1, node2, length=edge_length)\n",
    "\n",
    "first_coord = obstruction_data['GPS_Coordinates_Node1'].dropna().iloc[0]\n",
    "map_center = [float(coord) for coord in first_coord.split(', ')]\n",
    "\n",
    "# Create the Folium map\n",
    "mymap = folium.Map(location=map_center, zoom_start=15)\n",
    "title_html = \"\"\"\n",
    "    <h3 align=\"center\" style=\"font-size:16px\"><b>Skyway Network of Sydney CBD</b></h3>\n",
    "    \"\"\"\n",
    "mymap.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "# For adding nodes to the map\n",
    "for node in graph.nodes():\n",
    "    row = obstruction_data[obstruction_data['Node1'] == node]\n",
    "    if not row.empty:\n",
    "        gps_coordinates = [float(coord) for coord in row['GPS_Coordinates_Node1'].iloc[0].split(', ')]\n",
    "        folium.Marker(gps_coordinates, popup=f'{node}').add_to(mymap)\n",
    "\n",
    "# For adding edges to the map\n",
    "for edge in graph.edges(data=True):\n",
    "    row1 = obstruction_data[obstruction_data['Node1'] == edge[0]]\n",
    "    row2 = obstruction_data[obstruction_data['Node2'] == edge[1]]\n",
    "\n",
    "    if not row1.empty and not row2.empty:\n",
    "        coordinates_node1 = [float(coord) for coord in row1['GPS_Coordinates_Node1'].iloc[0].split(', ')]\n",
    "        coordinates_node2 = [float(coord) for coord in row2['GPS_Coordinates_Node2'].iloc[0].split(', ')]\n",
    "\n",
    "        edge_info = f\"{edge[0]}_{edge[1]}_{edge[2]['length']}\"\n",
    "        edge_color = \"#{:06x}\".format(hash(edge_info) & 0xFFFFFF)\n",
    "        edge_label = f\"Edge Length: {edge[2]['length']:.2f} km\"\n",
    "\n",
    "        folium.PolyLine(\n",
    "            [coordinates_node1, coordinates_node2],\n",
    "            color=edge_color,\n",
    "            weight=2.5,\n",
    "            opacity=1,\n",
    "            popup=edge_label\n",
    "        ).add_to(mymap)\n",
    "\n",
    "# Skyway Map with LoS-based skyway Segments and Nodes\n",
    "mymap.save('skyway_network_cbd.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad3ec9a6-5431-41fe-81fc-82f5b666c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract node names, segment length, building (i.e., nodes) heights, and node types from the graph\n",
    "nodes_data = []\n",
    "for node in graph.nodes(data=True):\n",
    "    node_id = node[0]\n",
    "\n",
    "    row = obstruction_data[obstruction_data['Node1'] == node_id]\n",
    "    if not row.empty:\n",
    "        gps = row['GPS_Coordinates_Node1'].iloc[0]\n",
    "        height = row['Height_Node1'].iloc[0] \n",
    "        btype = row['Node1_Type'].iloc[0]\n",
    "    else:\n",
    "        row = obstruction_data[obstruction_data['Node2'] == node_id]\n",
    "        if not row.empty:\n",
    "            gps = row['GPS_Coordinates_Node2'].iloc[0]\n",
    "            height = row['Height_Node2'].iloc[0]  \n",
    "            btype = row['Node2_Type'].iloc[0]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    node_data = {\n",
    "        'Node': node_id,\n",
    "        'GPS_Coordinates': gps,\n",
    "        'Building_Height': height,\n",
    "        'Building_Type': btype\n",
    "    }\n",
    "    nodes_data.append(node_data)\n",
    "\n",
    "# Extract edges/skyway segments\n",
    "edges_data = []\n",
    "for edge in graph.edges(data=True):\n",
    "    edge_data = {\n",
    "        'Node1': edge[0],\n",
    "        'Node2': edge[1],\n",
    "        'Edge_Length(Km)': edge[2]['length'],\n",
    "    }\n",
    "    edges_data.append(edge_data)\n",
    "\n",
    "\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "edges_df = pd.DataFrame(edges_data)\n",
    "\n",
    "result_df = pd.merge(edges_df, nodes_df, left_on='Node1', right_on='Node', how='left')\n",
    "result_df.rename(columns={\n",
    "    'GPS_Coordinates': 'GPS_Coordinates_Node1', \n",
    "    'Building_Type': 'Building_Type_Node1', \n",
    "    'Building_Height': 'Building_Height_Node1'\n",
    "}, inplace=True)\n",
    "result_df = pd.merge(result_df, nodes_df, left_on='Node2', right_on='Node', how='left', suffixes=('', '_Node2'))\n",
    "result_df.rename(columns={\n",
    "    'GPS_Coordinates': 'GPS_Coordinates_Node2', \n",
    "    'Building_Type': 'Building_Type_Node2', \n",
    "    'Building_Height': 'Building_Height_Node2'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "result_df.drop(['Node', 'Node_Node2'], axis=1, inplace=True)\n",
    "result_df.to_csv('Skyway_network_data_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd9f0096-ea1b-44bb-abad-3e88209412ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Skyway_network_data_check.csv'\n",
    "skyway_df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to calculate the geodesic distance in kilometers\n",
    "def calculate_distance(row):\n",
    "    # Parse the GPS coordinates\n",
    "    node1_coords = tuple(map(float, row['GPS_Coordinates_Node1'].split(', ')))\n",
    "    node2_coords = tuple(map(float, row['GPS_Coordinates_Node2'].split(', ')))\n",
    "    # Calculate the distance\n",
    "    return geodesic(node1_coords, node2_coords).kilometers\n",
    "skyway_df['Edge_Length(Km)'] = skyway_df.apply(calculate_distance, axis=1)\n",
    "\n",
    "updated_file_path = 'Skyway_network_data_check.csv'\n",
    "skyway_df.to_csv(updated_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4114b75f-556d-4c50-a2fb-254f55f65fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Skyway_network_data_check.csv'\n",
    "skyway_data = pd.read_csv(input_file)\n",
    "\n",
    "# Add a unique Segment ID to each edge\n",
    "skyway_data['Segment_ID'] = ['SEG' + str(i+1) for i in range(len(skyway_data))]\n",
    "output_file = 'Skyway_network_data_check.csv'\n",
    "skyway_data.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e30274b5-716c-4f59-87fc-1fe455e27af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skyway_data = pd.read_csv('Skyway_network_data_check.csv')\n",
    "\n",
    "# Create a set of unique node IDs\n",
    "unique_nodes = pd.unique(skyway_data[['Node1', 'Node2']].values.ravel())\n",
    "\n",
    "# Create a mapping of nodes to unique IDs\n",
    "node_id_map = {node: f'Node_{i+1}' for i, node in enumerate(unique_nodes)}\n",
    "\n",
    "# Add unique Node IDs to the original DataFrame\n",
    "skyway_data['Node1_ID'] = skyway_data['Node1'].map(node_id_map)\n",
    "skyway_data['Node2_ID'] = skyway_data['Node2'].map(node_id_map)\n",
    "\n",
    "output_file = 'Skyway_network_data_check.csv'\n",
    "skyway_data.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb142d2b-8d31-426a-82ad-23b538aefc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "skyway_data = pd.read_csv('Skyway_network_data_check.csv')\n",
    "\n",
    "# Create a new column that represents the undirected edge (a sorted tuple of Node1_ID and Node2_ID)\n",
    "skyway_data['Edge_Key'] = skyway_data.apply(lambda row: tuple(sorted([row['Node1_ID'], row['Node2_ID']])), axis=1)\n",
    "\n",
    "# Create a dictionary to ensure consistent Segment_ID assignment\n",
    "segment_id_map = {}\n",
    "\n",
    "for index, row in skyway_data.iterrows():\n",
    "    edge_key = row['Edge_Key']\n",
    "    if edge_key not in segment_id_map:\n",
    "        # Assign the current Segment_ID if not already assigned\n",
    "        segment_id_map[edge_key] = row['Segment_ID']\n",
    "    else:\n",
    "        # Update the Segment_ID in the current row for consistency\n",
    "        skyway_data.at[index, 'Segment_ID'] = segment_id_map[edge_key]\n",
    "\n",
    "# Drop the temporary Edge_Key column as it's no longer needed\n",
    "skyway_data = skyway_data.drop(columns=['Edge_Key'])\n",
    "\n",
    "output_file = 'Skyway_network_data_check.csv'\n",
    "skyway_data.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9c85c90-37f6-48e2-aa06-869ba98a2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"Skyway_network_data_check.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Drop rows where Node1 and Node2 are the same\n",
    "df_filtered = df[df['Node1'] != df['Node2']]\n",
    "output_file = \"Skyway_network_data_check.csv\"\n",
    "df_filtered.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3691bbbb-3dcd-4815-b690-d19d756d9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Skyway_network_data_check.csv'\n",
    "backup_file = 'Skyway_network_data_backupFile.csv'\n",
    "output_file = 'Skyway_network_data_checkF.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "backup_df = df.copy()\n",
    "backup_df.to_csv(backup_file, index=False)\n",
    "\n",
    "# Drop rows where building height is greater than 120 meters (400 ft) as per CASA regulations\n",
    "df = df[(df['Building_Height_Node1'] <= 120) &\n",
    "        (df['Building_Height_Node2'] <= 120) ]\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d51794b-69cd-4b37-a095-9125b8dd4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Skyway_network_data_checkF.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Define segment dimensions as per the dimensions of DJI phantom 3\n",
    "incoming_lane_height = 0.3  # meters\n",
    "separation_between_lanes = 0.1  # meters\n",
    "outgoing_lane_height = 0.3  # meters\n",
    "\n",
    "# Total height = incoming + separation + outgoing\n",
    "total_segment_height = incoming_lane_height + separation_between_lanes + outgoing_lane_height\n",
    "segment_width = 0.3  # meters (fixed for all segments)\n",
    "\n",
    "df['Incoming_Lane_Height'] = incoming_lane_height\n",
    "df['Outgoing_Lane_Height'] = outgoing_lane_height\n",
    "df['Lane_Separation'] = separation_between_lanes\n",
    "df['Segment_Height'] = total_segment_height\n",
    "df['Segment_Width'] = segment_width\n",
    "\n",
    "df.rename(columns={'Edge_Length(Km)': 'Segment_Length'}, inplace=True)\n",
    "df.to_csv(input_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43b626d0-85e0-4fcc-8b82-b96700210647",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"Skyway_network_data_checkF.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Function to convert GPS coordinates to XYZ coordinates\n",
    "def gps_to_xyz(lat, lon, altitude):\n",
    "    # Radius of Earth in meters\n",
    "    R = 6371000\n",
    "    lat_rad = np.radians(lat)\n",
    "    lon_rad = np.radians(lon)\n",
    "    \n",
    "    x = (R + altitude) * np.cos(lat_rad) * np.cos(lon_rad)\n",
    "    y = (R + altitude) * np.cos(lat_rad) * np.sin(lon_rad)\n",
    "    z = (R + altitude) * np.sin(lat_rad)\n",
    "    return x, y, z\n",
    "\n",
    "# Function to generate cuboid geometry for each segment\n",
    "def generate_geometry(row):\n",
    "    # Parse GPS coordinates\n",
    "    lat1, lon1 = map(float, row[\"GPS_Coordinates_Node1\"].split(\", \"))\n",
    "    lat2, lon2 = map(float, row[\"GPS_Coordinates_Node2\"].split(\", \"))\n",
    "    # Determine the maximum height between the two nodes\n",
    "    max_height = max(row[\"Building_Height_Node1\"], row[\"Building_Height_Node2\"])\n",
    "    # Segment height remains the same\n",
    "    segment_height = row[\"Segment_Height\"]\n",
    "    # Convert GPS coordinates and height to XYZ coordinates using the maximum height\n",
    "    x1, y1, z1 = gps_to_xyz(lat1, lon1, max_height)\n",
    "    x2, y2, z2 = gps_to_xyz(lat2, lon2, max_height)\n",
    "    # Ensure Z-coordinates consistency for reversed rows\n",
    "    z_adjusted = max_height + (segment_height / 2)\n",
    "    z1, z2 = z_adjusted, z_adjusted\n",
    "\n",
    "    # Create a geometry dictionary\n",
    "    geometry = {\n",
    "        \"start\": {\"x\": x1, \"y\": y1, \"z\": z1},\n",
    "        \"end\": {\"x\": x2, \"y\": y2, \"z\": z2},\n",
    "        \"width\": row[\"Segment_Width\"],\n",
    "        \"height\": segment_height,\n",
    "    }\n",
    "    return geometry\n",
    "\n",
    "# Apply the function to each row and create a new column for geometry\n",
    "df[\"Segment_Geometry\"] = df.apply(generate_geometry, axis=1)\n",
    "output_file = \"Skyway_network_data_checkF.csv\"\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4350bc75-54f0-405a-9676-0dbc233835d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"Skyway_network_data_checkF.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Function to calculate Euclidean distance between two 3D points\n",
    "def euclidean_distance(point1, point2):\n",
    "    return sqrt((point1[\"x\"] - point2[\"x\"])**2 + (point1[\"y\"] - point2[\"y\"])**2 + (point1[\"z\"] - point2[\"z\"])**2)\n",
    "\n",
    "# Function to generate a 3D bounding box (cuboid) for a segment\n",
    "def generate_cuboid(segment):\n",
    "    start = segment[\"start\"]\n",
    "    end = segment[\"end\"]\n",
    "    width = segment[\"width\"]\n",
    "    height = segment[\"height\"]\n",
    "    x_min, x_max = min(start[\"x\"], end[\"x\"]), max(start[\"x\"], end[\"x\"])\n",
    "    y_min, y_max = min(start[\"y\"], end[\"y\"]), max(start[\"y\"], end[\"y\"])\n",
    "    z_min, z_max = min(start[\"z\"], end[\"z\"]), max(start[\"z\"], end[\"z\"])\n",
    "    x_min -= width / 2\n",
    "    x_max += width / 2\n",
    "    z_max += height\n",
    "    \n",
    "    return box(x_min, y_min, x_max, y_max), z_min, z_max, start, end\n",
    "\n",
    "# Function to calculate 3D volume of an intersection\n",
    "def calculate_intersection_volume(intersection, z_min1, z_max1, z_min2, z_max2):\n",
    "    if not isinstance(intersection, Polygon):\n",
    "        return 0\n",
    "    z_overlap = max(0, min(z_max1, z_max2) - max(z_min1, z_min2))\n",
    "    return intersection.area * z_overlap\n",
    "\n",
    "# Function to check intersection of two cuboids\n",
    "def check_intersection(cuboid1, cuboid2, z_min1, z_max1, z_min2, z_max2, start1, end1, start2, end2):\n",
    "    intersection_2d = cuboid1.intersection(cuboid2)\n",
    "    if intersection_2d.is_empty:\n",
    "        return False\n",
    "    if z_max1 <= z_min2 or z_max2 <= z_min1:\n",
    "        return False\n",
    "    volume = calculate_intersection_volume(intersection_2d, z_min1, z_max1, z_min2, z_max2)\n",
    "    if (\n",
    "        euclidean_distance(start1, start2) <= 6 or euclidean_distance(start1, end2) <= 6 or\n",
    "        euclidean_distance(end1, start2) <= 6 or euclidean_distance(end1, end2) <= 6\n",
    "    ) and volume > 0.3:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Pre-parse geometry column\n",
    "df[\"Segment_Geometry_Parsed\"] = df[\"Segment_Geometry\"].apply(literal_eval)\n",
    "intersections = []\n",
    "for i in range(len(df)):\n",
    "    row1 = df.iloc[i]\n",
    "    geom1 = row1[\"Segment_Geometry_Parsed\"]\n",
    "    cuboid1, z_min1, z_max1, start1, end1 = generate_cuboid(geom1)\n",
    "\n",
    "    for j in range(i + 1, len(df)):\n",
    "        row2 = df.iloc[j]\n",
    "        geom2 = row2[\"Segment_Geometry_Parsed\"]\n",
    "\n",
    "        # Skip reverse segments\n",
    "        if {row1[\"Node1\"], row1[\"Node2\"]} == {row2[\"Node1\"], row2[\"Node2\"]}:\n",
    "            continue\n",
    "\n",
    "        cuboid2, z_min2, z_max2, start2, end2 = generate_cuboid(geom2)\n",
    "        if check_intersection(cuboid1, cuboid2, z_min1, z_max1, z_min2, z_max2, start1, end1, start2, end2):\n",
    "            intersection_point = cuboid1.intersection(cuboid2)\n",
    "            intersections.append({\n",
    "                \"Segment1_ID\": row1[\"Segment_ID\"],\n",
    "                \"Segment2_ID\": row2[\"Segment_ID\"],\n",
    "                \"Intersection_Point\": intersection_point.bounds\n",
    "            })\n",
    "\n",
    "intersection_df = pd.DataFrame(intersections)\n",
    "intersection_df.to_csv('check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41a6fe40-02b9-4ff9-8deb-a5bfefc99d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of intersecting segments\n",
    "intersecting_segments = set()\n",
    "for _, row in intersection_df.iterrows():\n",
    "    intersecting_segments.add(row[\"Segment1_ID\"])\n",
    "    intersecting_segments.add(row[\"Segment2_ID\"])\n",
    "\n",
    "retain_segments = set()\n",
    "drop_segments = []\n",
    "\n",
    "for _, row in intersection_df.iterrows():\n",
    "    seg1 = row[\"Segment1_ID\"]\n",
    "    seg2 = row[\"Segment2_ID\"]\n",
    "    length1 = df[df[\"Segment_ID\"] == seg1][\"Segment_Length\"].values[0]\n",
    "    length2 = df[df[\"Segment_ID\"] == seg2][\"Segment_Length\"].values[0]\n",
    "    \n",
    "    if length1 >= length2:\n",
    "        retain_segments.add(seg1)\n",
    "        drop_segments.append(seg2)\n",
    "    else:\n",
    "        retain_segments.add(seg2)\n",
    "        drop_segments.append(seg1)\n",
    "\n",
    "# Retain non-intersecting segments\n",
    "non_intersecting_segments = set(df[\"Segment_ID\"]) - intersecting_segments\n",
    "retain_segments.update(non_intersecting_segments)\n",
    "\n",
    "# Filter the original DataFrame\n",
    "retained_df = df[df[\"Segment_ID\"].isin(retain_segments)]\n",
    "dropped_segments_df = df[df[\"Segment_ID\"].isin(drop_segments)]\n",
    "retained_df.to_csv(\"Skyway_network_data_retained.csv\", index=False)\n",
    "dropped_segments_df.to_csv(\"Skyway_network_data_dropped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80889b28-0714-4694-a1cd-3bc8c96c9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Skyway_network_data_retained.csv\")\n",
    "\n",
    "# Add new columns for rooftop areas\n",
    "df[\"Rooftop_Area_Node1\"] = 0.0\n",
    "df[\"Rooftop_Area_Node2\"] = 0.0\n",
    "# Dictionary for caching computed areas\n",
    "area_cache = {}\n",
    "\n",
    "# Function to fetch rooftop area by GPS cooridnates + node names\n",
    "def fetch_rooftop_area(lat, lon, expected_name):\n",
    "    # Create a key combining GPS and node name (cleaned)\n",
    "    coord_key = f\"{lat:.7f},{lon:.7f}-{expected_name.strip().lower()}\"\n",
    "    if coord_key in area_cache:\n",
    "        return area_cache[coord_key]\n",
    "\n",
    "    def try_fetch(dist):\n",
    "        tags = {\"building\": True}\n",
    "        gdf = ox.features_from_point(center_point=(lat, lon), tags=tags, dist=dist)\n",
    "        buildings = gdf[gdf.geometry.type == \"Polygon\"]\n",
    "        if buildings.empty:\n",
    "            return None\n",
    "\n",
    "        buildings_proj = buildings.to_crs(buildings.estimate_utm_crs())\n",
    "        if 'name' in buildings_proj.columns:\n",
    "            buildings_proj['name'] = buildings_proj['name'].astype(str).str.strip().str.lower()\n",
    "            expected_clean = expected_name.strip().lower()\n",
    "            match = buildings_proj[buildings_proj['name'] == expected_clean]\n",
    "            if not match.empty:\n",
    "                return match.geometry.area.min()\n",
    "        return buildings_proj.geometry.area.min()\n",
    "    try:\n",
    "        area = try_fetch(40)\n",
    "        if area is None:\n",
    "            area = try_fetch(50)\n",
    "        result = area if area is not None else 0.0\n",
    "        area_cache[coord_key] = result\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error at ({lat}, {lon}) for '{expected_name}': {e}\")\n",
    "        area_cache[coord_key] = 0.0\n",
    "        return 0.0\n",
    "\n",
    "# Loop through each row and compute rooftop areas\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        lat1, lon1 = map(float, row[\"GPS_Coordinates_Node1\"].split(\",\"))\n",
    "        lat2, lon2 = map(float, row[\"GPS_Coordinates_Node2\"].split(\",\"))\n",
    "        name1 = str(row[\"Node1\"])\n",
    "        name2 = str(row[\"Node2\"])\n",
    "\n",
    "        df.at[idx, \"Rooftop_Area_Node1\"] = fetch_rooftop_area(lat1, lon1, name1)\n",
    "        df.at[idx, \"Rooftop_Area_Node2\"] = fetch_rooftop_area(lat2, lon2, name2)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping row {idx}: {e}\")\n",
    "\n",
    "df.to_csv(\"Skyway_network_data_retained.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83950763-dff0-4aad-96f0-f98e8b213b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Skyway_network_data_retained.csv\")\n",
    "\n",
    "# Rooftop areas reflect only 1.31%-11.6% (take average=6.4%=0.064) usable space\n",
    "df[\"Usable_Rooftop_Area_Node1(m^2)\"] = df[\"Rooftop_Area_Node1\"] * 0.064\n",
    "df[\"Usable_Rooftop_Area_Node2(m^2)\"] = df[\"Rooftop_Area_Node2\"] * 0.064\n",
    "df.to_csv(\"Skyway_network_data_retained.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc610b2d-2bb5-4a27-a04f-22f472496ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'Skyway_network_data_retained.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Pad dimensions and spacing\n",
    "PAD_WIDTH = 1.35  # meters\n",
    "SPACING = 1.0     # meters\n",
    "\n",
    "# Effective area per pad with spacing\n",
    "EFFECTIVE_PAD_AREA_M2 = (PAD_WIDTH + SPACING) ** 2\n",
    "MIN_PAD_COUNT = 2\n",
    "\n",
    "df = df[\n",
    "    (df['Usable_Rooftop_Area_Node1(m^2)'] <= 100) &\n",
    "    (df['Usable_Rooftop_Area_Node2(m^2)'] <= 100)\n",
    "]\n",
    "#Function to compute the number of charging and waiting pads per node\n",
    "def compute_half_pad_pairs(rooftop_area):\n",
    "    try:\n",
    "        half_area = rooftop_area / 2\n",
    "        pad_count = math.floor(half_area / EFFECTIVE_PAD_AREA_M2)\n",
    "        return max(pad_count, MIN_PAD_COUNT)\n",
    "    except Exception as e:\n",
    "        return MIN_PAD_COUNT\n",
    "\n",
    "df['Recharging_Pads_Node1'] = df['Usable_Rooftop_Area_Node1(m^2)'].apply(compute_half_pad_pairs)\n",
    "df['Waiting_Pads_Node1'] = df['Usable_Rooftop_Area_Node1(m^2)'].apply(compute_half_pad_pairs)\n",
    "df['Recharging_Pads_Node2'] = df['Usable_Rooftop_Area_Node2(m^2)'].apply(compute_half_pad_pairs)\n",
    "df['Waiting_Pads_Node2'] = df['Usable_Rooftop_Area_Node2(m^2)'].apply(compute_half_pad_pairs)\n",
    "\n",
    "output_file = 'Skyway_network_data_retained.csv'\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d428e272-e806-4313-a4d7-ebdb02f536ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "skyway_data = pd.read_csv('Skyway_network_data_retained.csv')\n",
    "\n",
    "# Collect valid source-destination pairs\n",
    "new_data = []\n",
    "\n",
    "for index, row in skyway_data.iterrows():\n",
    "    # Case 1: Node1 is a destination\n",
    "    if row['Building_Type_Node1'] in ['apartments', 'hospital'] and row['Building_Type_Node2'] not in ['apartments', 'hospital']:\n",
    "        new_data.append({\n",
    "            'Source_Node': row['Node2'],\n",
    "            'Source_Type': row['Building_Type_Node2'],\n",
    "            'Source_Coordinates': row['GPS_Coordinates_Node2'],\n",
    "            'Destination_Node': row['Node1'],\n",
    "            'Destination_Type': row['Building_Type_Node1'],\n",
    "            'Destination_Coordinates': row['GPS_Coordinates_Node1'],\n",
    "            'Building_Height': row['Building_Height_Node1'],\n",
    "            'Type': row['Building_Type_Node1']\n",
    "        })\n",
    "\n",
    "    # Case 2: Node2 is a destination\n",
    "    if row['Building_Type_Node2'] in ['apartments', 'hospital'] and row['Building_Type_Node1'] not in ['apartments', 'hospital']:\n",
    "        new_data.append({\n",
    "            'Source_Node': row['Node1'],\n",
    "            'Source_Type': row['Building_Type_Node1'],\n",
    "            'Source_Coordinates': row['GPS_Coordinates_Node1'],\n",
    "            'Destination_Node': row['Node2'],\n",
    "            'Destination_Type': row['Building_Type_Node2'],\n",
    "            'Destination_Coordinates': row['GPS_Coordinates_Node2'],\n",
    "            'Building_Height': row['Building_Height_Node2'],\n",
    "            'Type': row['Building_Type_Node2']\n",
    "        })\n",
    "\n",
    "result_df = pd.DataFrame(new_data)\n",
    "result_df = result_df[result_df['Type'] != 'hospital']\n",
    "result_df.to_csv('Skyway_Source_Destination.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
